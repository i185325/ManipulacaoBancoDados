# -*- coding: utf-8 -*-
"""desafio2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10xespVf1vOra3NVEsyFHdduDQN2vmXfX
"""

# ==========================================
# desafio2 - Lab 02 em Python (Google Colab) - Só Cia AA
# ==========================================
# Objetivo:
# Ler o arquivo flights.csv.zip em blocos (chunks),
# calcular estatísticas de atrasos (>10 min) para a companhia AA,
# e gerar um calendário (heatmap) com os percentuais.
# ==========================================

# Importa as bibliotecas necessárias
import pandas as pd                # Para manipulação de dados (dataframes)
import matplotlib.pyplot as plt    # Para criar gráficos
import seaborn as sns              # Para visualização estatística (heatmap)
import zipfile                     # Para abrir o arquivo ZIP
from google.colab import files     # Para upload de arquivos no Colab

# ==========================================
# 1. Upload do arquivo ZIP
# ==========================================
print("Faça o upload do arquivo flights.csv.zip...")
uploaded = files.upload()  # Abre a janela no Colab para escolher o arquivo

# Nome esperado dentro do zip
zip_path = "flights.csv.zip"
csv_name = "flights.csv"

# Extrai o arquivo flights.csv de dentro do zip
with zipfile.ZipFile(zip_path, "r") as z:
    z.extract(csv_name, "/content/")
print(f"{csv_name} extraído com sucesso!")

# ==========================================
# 2. Função que processa cada pedaço (chunk)
# ==========================================
def getStats(chunk):
    # Filtra apenas a companhia AA
    chunk = chunk[chunk["AIRLINE"] == "AA"]

    # Remove linhas com valores ausentes (NA) nas colunas de interesse
    chunk = chunk.dropna(subset=["YEAR", "MONTH", "DAY", "ARRIVAL_DELAY"])

    # Converte colunas para os tipos corretos
    chunk["YEAR"] = chunk["YEAR"].astype(int)
    chunk["MONTH"] = chunk["MONTH"].astype(int)
    chunk["DAY"] = chunk["DAY"].astype(int)
    chunk["ARRIVAL_DELAY"] = chunk["ARRIVAL_DELAY"].astype(float)

    # Agrupa por data (ano, mês, dia)
    # Para cada grupo: conta total de voos e quantos tiveram atraso > 10 min
    stats = chunk.groupby(["YEAR","MONTH","DAY"]).apply(
        lambda x: pd.Series({
            "total_flights": len(x),                        # total de voos
            "delayed_flights": (x["ARRIVAL_DELAY"] > 10).sum()  # atrasados
        }),
        include_groups=False
    ).reset_index()

    return stats

# ==========================================
# 3. Função que consolida todos os resultados
# ==========================================
def computeStats(all_stats):
    # Agrupa novamente por ano/mês/dia (caso venha de vários chunks)
    combined = all_stats.groupby(["YEAR","MONTH","DAY"]).agg({
        "total_flights":"sum",
        "delayed_flights":"sum"
    }).reset_index()

    # Calcula o percentual de atrasos
    combined["Perc"] = combined["delayed_flights"] / combined["total_flights"]

    # Cria coluna de data no formato padrão (AAAA-MM-DD)
    combined["Data"] = pd.to_datetime(combined[["YEAR","MONTH","DAY"]])

    # Retorna apenas as colunas finais de interesse
    return combined[["Data","Perc"]]

# ==========================================
# 4. Leitura em blocos (chunks) e consolidação
# ==========================================
chunk_size = 100_000  # Define o tamanho do bloco (100 mil linhas)
columns = ["YEAR","MONTH","DAY","AIRLINE","ARRIVAL_DELAY"]  # Colunas usadas
all_chunks = []  # Lista para acumular resultados parciais

# Leitura em pedaços usando pandas
for i, chunk in enumerate(pd.read_csv("/content/flights.csv", chunksize=chunk_size, usecols=columns)):
    print(f"Processando chunk {i+1}...")
    all_chunks.append(getStats(chunk))  # Processa cada pedaço

# Junta todos os pedaços em um único DataFrame
full_stats = pd.concat(all_chunks)

# Calcula as estatísticas finais
final_results = computeStats(full_stats)

print("Estatísticas finais calculadas!")
print(final_results.head())  # Mostra primeiras linhas

# ==========================================
# 5. Visualização em heatmap
# ==========================================
# Cria colunas auxiliares de semana e dia da semana
df = final_results.copy()
df["week_of_year"] = df["Data"].dt.isocalendar().week.astype(int)  # Semana ISO
df["day_of_week"] = df["Data"].dt.dayofweek  # Dia da semana (0=Seg ... 6=Dom)

# Cria tabela pivô: linhas = dias da semana, colunas = semanas
heatmap_data = df.pivot_table(
    index="day_of_week", columns="week_of_year", values="Perc"
)

# Reordena para que domingo (6) fique na primeira linha
heatmap_data = heatmap_data.reindex([6,0,1,2,3,4,5])
heatmap_data.index = ["Dom","Seg","Ter","Qua","Qui","Sex","Sab"]

# Cria o gráfico heatmap
plt.figure(figsize=(15,8))
sns.heatmap(
    heatmap_data,
    cmap="RdYlGn_r",                   # Paleta vermelho ↔ verde
    linewidths=.5, linecolor="lightgray",
    cbar_kws={"label":"% de atrasos"}  # Rótulo da barra de cores
)

# Ajustes do gráfico
plt.title("Percentual de Atrasos - AA (2015)", fontsize=16)
plt.xlabel("Semana do Ano", fontsize=12)
plt.ylabel("Dia da Semana", fontsize=12)
plt.yticks(rotation=0)  # Mantém nomes dos dias na horizontal
plt.tight_layout()
plt.show()